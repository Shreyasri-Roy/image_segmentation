# ðŸ¾ Oxford-IIIT Pet Image Segmentation (UNet, PyTorch)

This project prepares the Oxford-IIIT Pet Dataset and trains a UNet-based segmentation model to segment pet regions from images. It includes full preprocessing, model training, evaluation, and metric logging using PyTorch and Weights & Biases (WandB).
## Processed Data

- Dataset: Oxford-IIIT Pet Dataset
- Total Images: 3,686
- Each image has a corresponding processed mask with 3 classes:
  - 0 = Background
  - 1 = Pet
  - 2 = Border

This satisfies the assignmentâ€™s requirement to process 3,000 to 8,000 images.

---
### FULL CODE PIPELINE IS THERE IN `full_code_pipeline.pynb`: YOU CAN JUST RUN IT IN COLAB/ JUPYTER NOTEBOOK AND DO NOTHING ELSE.
### Otherwise follow below instructions:
## ðŸ“‚ Project Structure

    ðŸ“¦ project-root/
    â”œâ”€â”€ dataset/
    â”‚   â”œâ”€â”€ annotations
    â”‚   â”‚   â”œâ”€â”€ trimaps
    â”‚   â”‚   â””â”€â”€ ....
    â”‚   â”œâ”€â”€ images
    â”‚   â”‚   â”œâ”€â”€ Abyssinian_1.jpg
    â”‚   â”‚   â””â”€â”€ ....
    â”‚   â”œâ”€â”€ masks
    â”‚   â”‚   â”œâ”€â”€ Abyssinian_1.png
    â”‚   â”‚   â””â”€â”€ ...
    â”œâ”€â”€ prepare_dataset.py
    â”œâ”€â”€ train_unet.py (or .ipynb)
    â”œâ”€â”€ report.md
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ run.sh
    â”œâ”€â”€ wanb report.csv
    â”œâ”€â”€ full_code_pipeline.pynb
    â””â”€â”€ README.md


## âš™ï¸ Task 1: Dataset Preparation

- Downloads the Oxford-IIIT Pet Dataset.
- Converts `trimap` masks (original labels: 1=border, 2=pet, 3=background) to standard 0-based format:
  - 0 = Background
  - 1 = Pet
  - 2 = Border
- Resizes all images and masks to 128Ã—128.
- Splits data into **train / validation / test** sets.
- Output masks are saved in `.png` format for fast loading.

Run:
```bash
python prepare_dataset.py
```
Prepares dataset folder of the form:
## ðŸ“‚ Dataset Folder Structure

    ðŸ“¦ project-root/
    â”œâ”€â”€ dataset/
    â”‚   â”œâ”€â”€ annotations
    â”‚   â”‚   â”œâ”€â”€ trimaps
    â”‚   â”‚   â””â”€â”€ ....
    â”‚   â”œâ”€â”€ images
    â”‚   â”‚   â”œâ”€â”€ Abyssinian_1.jpg
    â”‚   â”‚   â””â”€â”€ ....
    â”‚   â”œâ”€â”€ masks
    â”‚   â”‚   â”œâ”€â”€ Abyssinian_1.png
    â”‚   â”‚   â””â”€â”€ ...

---

### âš ï¸ Edge Case Handling

- Trimap remapping: `(1, 2, 3) â†’ (2, 1, 0)`
- Labels outside `[1, 3]` clipped to background (`0`)
- Skips macOS system files like `._*.png`
- Masks resized using `Image.NEAREST` to avoid label interpolation
- Ensures one-to-one correspondence of image-mask pairs

---
## ðŸ¤– Task 2: UNet Model Training

Trains a **UNet** segmentation model using PyTorch. Logs training progress and performance metrics to **Weights & Biases (wandb.ai)**. Visualizes model predictions at each epoch.

### ðŸ”§ Training Specs

- **Optimizer:** Adam  
- **Loss Function:** CrossEntropy  
- **Input Size:** 128Ã—128  
- **Epochs:** 5  
- **Hardware:** GPU supported (e.g. Google Colab)

### âœ… Run

```bash
python train_unet.py
```

---
## ðŸ“ˆ Evaluation Metrics
---

Computed on validation and test sets:

- âœ… Pixel Accuracy  
- ðŸ“Š Intersection over Union (IoU)  
- ðŸ§ª Dice Score  

All metrics are automatically logged and visualized using **WandB**.

---

## ðŸš€ Reproducibility
---

To install dependencies:

```bash
pip install -r requirements.txt
```
 run.sh  -> Includes instructions to reproduce the results on a Linux environment.
---
### ðŸ™Œ Acknowledgements 
* **Dataset:** Oxford-IIIT Pet Dataset
* * **Model Architecture:** UNet
* *  **Experiment Logging:** Weights & Biases Report is present in **`wandb report.csv`**
* * **Experiment Logging:** [Weights & Biases]([https://wandb.ai](https://wandb.ai/shreyasriroy-indian-institute-of-science/oxford-pet-segmentation/runs/imp7h51g?nw=nwusershreyasriroysrmr))
---
